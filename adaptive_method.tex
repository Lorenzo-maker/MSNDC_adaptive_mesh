\section*{$p_n h$-ADAPTIVE MESH REFINEMENT METHOD}

In this section a $\pnh$-adaptive mesh refinement method is developed. In particular, the generic OCP problem is first transcribed into an NLP using the \emph{direct collocation} method, explained above, then the mesh refinement method is applied to the obtained optimal solution.
The $\pnh$ method explained here is closely related to~\cite{Patterson:OCAM:2015}. In particular, the method for estimating the error in the current solution is adapted from the aforementioned reference. The key novelty here is the refinement strategy.
In~\cite{Patterson:OCAM:2015}, the adjustment of the polynomial degree is perfomed such that all states are represented by the same degree. Instead, in this work, the $p$-refinement is different for each state. Instead, similarly to~\cite{Patterson:OCAM:2015}, the mesh spacing is adjusted only if the approach to reach convergence by solely increasing the polynomial degree fails.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Error Estimate}

In this section, an estimate of the relative error in the solution within a mesh interval is derived. The error is calculated in each mesh interval and for each component of the state.
The key idea is to compare the optimal state obtained from the NLP solution, with a more accurate approximation of the state.

To explain in details this aspect, let us consider the $i$-th state on the generic $S_k$ mesh interval.
The solution of NLP gives as an output a polynomial approximation of the state, namely $\Xkidki (\tau)$.
Under the assumption of a smooth solution, a polynomial approximation obtained with an increased number of Gauss-Legendre points should yield a state that more accurately complies with the dynamics.
Suppose that the error has to be estimated at a set of  $\dkip = \dki + 1$ collocation points denoted as $\taudkip$.
Then, on the one hand, the values of the NLP solution at these points are computed as $\Xkidki (\taudkip_j)$, ($j = 1, \dots, \dkip$).

On the other hand, a higher-order approximation of the state can be constructed by sampling the dynamics at these new Gauss-Legendre points $\taudkip$ and employing a Gauss quadrature formula.
Let $\barXkidkip (\tau)$ be a polynomial of degree $\dkip$ that is defined for the $i$-th state on the $S_k$ interval. If the derivative of this polynomial matches the dynamics at each $\taudkip$ collocation points, $\barXkidkip (\tau)$ can be obtained by a numerical integration using the resulting quadrature scheme
\begin{subequations}
\begin{align}
	&\barXkidkip (\tau) = \sum_{m=1}^{\dkip}\Big(\int_{0}^{\tau}\lmdki (\tau)d\tau\Big) f_i\Big(\Xkd(\taudkip_m), U_k\Big), \hspace{2mm} \text{with} \label{eq:barX}\\
	&  \lmdki (\tau) = \prod_{r=1, r\neq m}^{\dkip} \dfrac{\tau - \taudkip_r}{\taudkip_m - \taudkip_r}. \label{eq:meshlm}
\end{align}
\end{subequations}

Hence $\barXkidkip (\tau)$ represents the improved approximation and its values in $\taudkip$ will be denoted by $\barXkidkip (\taudkip_j)$, ($j = 1, \dots, \dkip$).

With the above quantities, the \emph{absolute} error $\Ekij$ and the \emph{relative} error $\ekij$ computed at each $\taudkip_j$ for the $i$-th state in the $k$-th interval are defined as
\begin{subequations}
	\begin{align}
	&\Ekij = \Big|\barXkidkip (\taudkip_j) - \Xkidki (\taudkip_j)\Big| \label{eq:absolute}\\
	&\ekij = \dfrac{\Ekij}{1 + \max\limits_{j= 1, \dots, \dkip} \Big| \Xkidki (\taudkip_j)\Big|} \label{eq:relative}
	\end{align}
\end{subequations}
The relative error in particular is the key ingredient used  in the next section to implement the $\pnh$-refinement strategy.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Algorithm}
In this section the algorithm implemented for mesh refining is illustrated.
Let us suppose that our goal is to keep the relative error $\ekij$ below a given tolerance $\epsilon$ in each mesh interval $S_k$, ($k = 1, \dots, N$). If the tolerance $\epsilon$  is not met at least in one mesh interval, then the next step is to refine the current mesh, either by dividing the mesh interval or increasing the degree of the approximating polynomial within the mesh interval.

For the sake of clarity, the method is shown as a pseudocode for the generic $S_k$ mesh interval. The Algorithm unfolds in two main passes: (i) the \emph{Exploration} pass and (ii) the \emph{Execution} pass.
To better understand the pseudocode, some quantities appearing in it are worth explaining from the outset.

With reference to {\bf Algorithm~\ref{alg:step1}}, $\dkis$ is the \emph{new} polynomial degree that is suggested by the algorithm, for the $i$-th state in the $S_k$ interval, to reach the prescribed tolerance $\epsilon$. The quantity $\Bki$ represents the number of subinterval into which $S_k$ should be split in order to meet the prescribed $\epsilon$ tolerance for the error of the $i$-th state component. If $\Bki = 1$, no subdivisions in $S_k$ are necessary. Correspondingly, if $\dkis = \dki$, no increment in the polynomial degree is required. Instead, $d_\text{min}$ and $d_\text{max}$ are the maximum and the minimum allowable polynomial degrees provided by the user.
%% Definire dmax, dmin, Bki, d*, epsilon
\begin{algorithm}
\caption{\emph{Exploration} pass of the $\pnh$ mesh refinement}\label{alg:step1}
	\begin{algorithmic}[1]
		\For {$i = 1$ to $n_x$}
			\If{$\max\limits_{j= 1, \dots, \dkip} (\ekij) \leq \epsilon$}
				\State $\dkis \gets \dki$ \Comment{degree ok}
				\State $\Bki \gets 1$     \Comment{mesh ok}
			\Else
				\State $\Pki \gets \log_{\dki} \Bigg\lceil \max\limits_{j= 1, \dots, \dkip} \Bigg(\dfrac{\ekij}{\epsilon}\Bigg) \Bigg\rceil$
				\State $\dkis \gets \dki + \Pki$ \Comment{increase degree}
					\If {$ \dkis \leq d_\text{max}$}
						\State $\Bki \gets 1$		
					\Else
						\State $\Bki \gets \max\Bigg(\Bigg\lceil \dfrac{\dkis}{d_\text{min}}\Bigg\rceil, 2\Bigg)$ \Comment{split mesh}
					\EndIf
			\EndIf
		\EndFor
	\end{algorithmic}
\end{algorithm}

According to {\bf Algorithm~\ref{alg:step1}}, the outcome of the Exploration pass is to collect three vectorial quantities: $\Dks = [\dksn{1}, \dots, \dksn{i}, \dots, \dksn{n_x}]$, $\Dk = [\dkg{1}, \dots, \dkg{i}, \dots, \dkg{n_x}]$, and $[B_{k,1}, \ldots, B_{k,i}, \ldots, B_{k,n_x}]$. The quantity $P_{k,i}$, playing a key role to compute $\dkis$, is calculated as suggested by~\cite{Patterson:OCAM:2015}, in accordance with the convergence theory summarized in~\cite{Hou:GNC:2012,Hou:PHD:2013}.

Roughly speaking, the outcome of the \emph{Exploration} pass does not provide a final answer \emph{per se}, but is only instrumental to the process of deciding whether the degree of the polynomial for each state component should be raised and/or the interval $S_k$ should be split. The actual of the action to take is performed in the \emph{Execution} pass and benefits from the comparison of the collected vectorial quantities.

The \emph{Execution} pass, presented in the form a pseudocode in {\bf Algorithm~\ref{alg:step2}} is now illustrated.
\begin{algorithm}
	\caption{\emph{Execution} pass of the $\pnh$ mesh refinement}\label{alg:step2}
	\begin{algorithmic}[1]
		\If {$\max\limits_{i= 1, \dots, n_x}(\Bki) = 1$}
			\If {$\Dks = \Dk$}
				\State algorithm.stop() \Comment convergence reached	
			\Else
				\For {$i = 1$ to $n_x$}
					\State $\dki \gets \dkis$ \Comment ${p_n}$-refinement
				\EndFor
			\EndIf
		\Else
			\For {$i = 1$ to $n_x$}
				\State $\dki \gets \dki$
				\State $\Bki \gets \max\limits_{i= 1, \dots, n_x}(\Bki)$ \Comment h-refinement
			\EndFor		
		\EndIf
	\end{algorithmic}
\end{algorithm}
The main idea is that, if all $\Bki$'s are equal to 1 and $\Dks = \Dk$, then the current mesh and polynomial degrees are sufficient to meet the prescribed tolerance. Therefore, no refinement is needed (convergence reached).

 Instead, if only all $\Bki$'s are equal to 1, then the collected $\dkis$ should replace the degrees of the polynomials, according to a $p_n$-refinement strategy (${p_n}$-refinement).

Alternatively, if at least one of the $\Bki$'s is greater than 1 -- for at least one state component a degree greater than $d_\text{max}$ was required (cf. line 11 in {\bf Algorithm~\ref{alg:step1}}) -- a subdivision of the ``responsible'' interval/intervals takes place while the degrees are kept to the starting values $\dki$, thus following a $h$-refinement strategy ($h$-refinement).

In any case, at the end of the Execution pass, the new mesh (to be employed in the discretization of the next NLP to be solved), is encoded in the quantity $\dki$ and $\Bki$ for $i = 1, \dots, n_x$ and for $k = 1, \dots, N$.

After the solution of the new NLP with the refined mesh, the same strategy can be applied until convergence. Converge is obtained when hitting line 3 of {\bf Algorithm~\ref{alg:step2}}.

%It is worth to notice that, as explained in Alg.~\ref{alg:step2}, in each interval, if at least one of the state required to split $S_k$, then it is splitted. Instead if no state required it, each state is approximated, in the next NLP, with a polynomial of degree equal to the one proposed by the method.

It is worth observing that the proposed algorithm can match the original mesh refinement method in~\cite{Patterson:OCAM:2015} if the following assumptions are made: (i) The initial NLP is set up such that all the state components have the same degree $d_k$ in $S_k$, therefore, $\dki = d_k$ ($i = 1, \dots, n_x$); (ii) line 6 of {\bf Algorithm~\ref{alg:step2}} is modified according to $\dki = \max\limits_{i= 1, \dots, n_x}(\dkis)$. In this manner, the polynomial approximation maintains always the same degree for all the states.



